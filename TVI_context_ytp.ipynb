{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_qHfV_LvLZ"
      },
      "source": [
        "This notebook:\n",
        "\n",
        "transformational variability analysis for context (sample 1 vs sample 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9FEvz2gQFn1"
      },
      "outputs": [],
      "source": [
        "!pip install dpca"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "jv9SMm3WrRZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vkbL7OI_7IL"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/My Drive/dpca_code_V2\n",
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import dpca as dp\n",
        "from scipy import io\n",
        "from scipy import stats\n",
        "import scipy.io as sio\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def center(data):\n",
        "    \"\"\"\n",
        "    Center data in an S x N x K matrix\n",
        "    by average over all S and N indices\n",
        "    \"\"\"\n",
        "    return data - np.vstack(data).mean(0)"
      ],
      "metadata": {
        "id": "15negcBD1TnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TVI analysis"
      ],
      "metadata": {
        "id": "33Un4lEOhLR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/roi_new_with_cue1_type\n",
        "#conditions=[PMI_ori;UMI_ori;PMI_loc;UMI_loc;Cue1;ori_1,ori_2,loc_1,loc_2,cue_switch,PMI_ori_2,UMI_ori_2,PMI_loc_2,UMI_loc_2];\n",
        "num_sub = 13\n",
        "sublist = ['02','03','04','07','08','09','10','11','12','16','17','18','19']\n",
        "r_spearman = []\n",
        "p_spearman = []\n",
        "dist_lower = []\n",
        "dist_higher = []\n",
        "for sub in range(num_sub):\n",
        "    matdata2 = sio.loadmat(f'/content/gdrive/My Drive/roi_new_with_cue1_type/POCONN4_{sublist[sub]}_all_trials_delay2_500_roi18to23.mat')\n",
        "    filename = f'POCONN4_{sublist[sub]}_all_trials_delay2_500_roi25.mat'\n",
        "    matdata = sio.loadmat(filename) #trial_pat(324x500x20), conditions, angle_error1, angle_error2\n",
        "\n",
        "    #S x T x N for data format\n",
        "    trial_pat = matdata['trial_pat']\n",
        "    conditions = matdata2['conditions'] #note this is matdata2\n",
        "    angle_error1 = matdata2['angle_error1']\n",
        "    angle_error2 = matdata2['angle_error2']\n",
        "\n",
        "    ori_stim = np.unique(conditions[5,:])\n",
        "    ori_stim1 = conditions[5,:]\n",
        "    ori_stim2 = conditions[6,:]\n",
        "\n",
        "    stim1_avg = np.zeros((len(ori_stim),trial_pat.shape[2], trial_pat.shape[1]))\n",
        "    stim2_avg = np.zeros((len(ori_stim),trial_pat.shape[2], trial_pat.shape[1]))\n",
        "\n",
        "    for i, iori in enumerate(ori_stim):\n",
        "        iepochs = np.argwhere(ori_stim1 == iori)\n",
        "        stim1_avg[i] = np.squeeze(trial_pat[iepochs, :, :].mean(0).T)\n",
        "\n",
        "        iepochs = np.argwhere(ori_stim2 == iori)\n",
        "        stim2_avg[i] = np.squeeze(trial_pat[iepochs, :, :].mean(0).T)\n",
        "\n",
        "    TRs = np.array((4,5,6))\n",
        "\n",
        "    # For Sample 1 subspace\n",
        "    # stim1_tmp = center(stim1_avg[:,TRs,:])\n",
        "    # stim1_model = dp.dPCA(stim1_tmp, n_dim = 2, old_version=True)\n",
        "    # d = stim1_model.decoder\n",
        "\n",
        "    # For Sample 2 subspace\n",
        "    stim2_tmp = center(stim2_avg[:,TRs,:])\n",
        "    stim2_model = dp.dPCA(stim2_tmp, n_dim = 2, old_version=True)\n",
        "    d = stim2_model.decoder\n",
        "\n",
        "    Xstim1 = np.matmul(center(stim1_avg),d)\n",
        "    Xstim2 = np.matmul(center(stim2_avg),d)\n",
        "\n",
        "    xystim1 = Xstim1[:,TRs,:].mean(1)\n",
        "    xystim2 = Xstim2[:,TRs,:].mean(1)\n",
        "\n",
        "    normdist = np.zeros((9))\n",
        "\n",
        "    for iori in range(9):\n",
        "        normdist[iori] = math.sqrt(((xystim1[iori,0]-xystim2[iori,0])**2)+((xystim1[iori,1]-xystim2[iori,1])**2))\n",
        "\n",
        "    Xindivtrials = np.matmul(center(trial_pat.transpose((0,2,1))),d)\n",
        "    num_trials = len(Xindivtrials)\n",
        "\n",
        "    trdist = []\n",
        "    trnormdist = []\n",
        "\n",
        "    xygen = xystim2 #For Sample 2 subspace\n",
        "    origen = ori_stim2\n",
        "    for tr in range(num_trials):\n",
        "          xytrial = Xindivtrials[tr,TRs,:].mean(0)\n",
        "          trdist += [math.sqrt(((xytrial[0]-xygen[origen[tr]-1,0])**2)+((xytrial[1]-xygen[origen[tr]-1,1])**2))]\n",
        "          trnormdist += [trdist[-1] / normdist[origen[tr]-1]]\n",
        "\n",
        "    angle_error_abs = np.squeeze(abs(angle_error1)) #select which error to use\n",
        "    trnormdist = np.array(trnormdist)\n",
        "    sorted_dist = trnormdist[angle_error_abs.argsort()]\n",
        "    dist_lower = np.append(dist_lower, np.mean(sorted_dist[:round(num_trials/2)]))\n",
        "    dist_higher = np.append(dist_higher, np.mean(sorted_dist[round(num_trials/2):]))\n",
        "\n",
        "# Calculate the correlation between TVI and error for each subject\n",
        "#     r,p = stats.spearmanr(np.array(trnormdist),np.squeeze(abs(angle_error2)), alternative = 'greater')\n",
        "#     r_spearman = np.append(r_spearman,round(r,2))\n",
        "#     p_spearman = np.append(p_spearman,round(p,3))\n",
        "#     print(sub)\n",
        "\n",
        "# print(r_spearman)\n",
        "# print(p_spearman)\n",
        "# print(sum(p_spearman<0.05))\n",
        "\n",
        "################# bar plot of transformational efficacy in Sample 1 space by response accuracy\n",
        "A_lower = np.mean(dist_lower)\n",
        "A_lower_err = stats.sem(dist_lower)\n",
        "A_higher = np.mean(dist_higher)\n",
        "A_higher_err = stats.sem(dist_higher)\n",
        "print('lower M:', np.round(A_lower,2), 'higher M:', np.round(A_higher,2))\n",
        "print('lower SEM:', np.round(A_lower_err,2), 'higher SEM:', np.round(A_higher_err,2))\n",
        "xvals = [1,2]\n",
        "yvals = [A_lower, A_higher]\n",
        "error = [A_lower_err, A_higher_err]\n",
        "accuracies = ['low error','high error']\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.bar(xvals, yvals, yerr=error, align='center', alpha=0.5, ecolor='b', capsize=10)\n",
        "ax.set_ylabel('Stim1 subspace distance index')\n",
        "ax.set_xticks(xvals)\n",
        "ax.set_xticklabels(accuracies)\n",
        "ax.yaxis.grid(False)\n",
        "ax.set_title('FEF Recall 1 Stim2 subspace')\n",
        "\n",
        "stats.ttest_rel(dist_lower,dist_higher,alternative='less')"
      ],
      "metadata": {
        "id": "jDFtWte2rtlJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}